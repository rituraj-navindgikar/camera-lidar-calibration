{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a543a21-4c20-4879-a749-fe4264bcf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb0684-42e8-4130-aee7-c6568e908fdf",
   "metadata": {},
   "source": [
    "**Algorithm 2: Joint optimization of time offset and extrinsics**\n",
    "\n",
    "Given:\n",
    "  - Precomputed camera data:\n",
    "    - `pipeline` with:\n",
    "        - `images[frame_id]`\n",
    "        - `edge_maps[frame_id]`\n",
    "        - `dist_transforms[frame_id]`\n",
    "    - `cam_times`  (array of camera timestamps [sec])\n",
    "    - `frame_ids`  (array of frame_ids aligned with cam_times)\n",
    "    - Camera intrinsics `K` (3×3)\n",
    "  - LiDAR scans (list of dicts):\n",
    "    - For each scan `s`:\n",
    "        - `s[\"timestamp_sec\"]`  (LiDAR time [sec])\n",
    "        - `s[\"points\"]`         (N×3 array of LiDAR-frame points)\n",
    "  - Initial LiDAR→camera transform `T_CL_init` (4×4)\n",
    "\n",
    "We want to find:\n",
    "  - `params = [tau, rx, ry, rz, tx, ty, tz]`\n",
    "  - that minimize:  `objective(params) = - mean_edge_score`.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Define helper transforms**\n",
    "\n",
    "1.1. Convert small Euler angles to rotation matrix:\n",
    "  - `R_delta = euler_to_R(rx, ry, rz)`.\n",
    "\n",
    "1.2. Build correction transform:\n",
    "  - `T_delta = make_T(R_delta, [tx, ty, tz])`.\n",
    "\n",
    "1.3. Updated LiDAR→camera transform:\n",
    "  - `T_CL = T_CL_init @ T_delta`.\n",
    "\n",
    "1.4. Transform LiDAR points to camera frame:\n",
    "  - For each point `p_L`:\n",
    "      - `p_C = T_CL * [p_L; 1]` (homogeneous).\n",
    "  - Collect into array `points_C`.\n",
    "\n",
    "1.5. Project camera-frame points to pixels using intrinsics:\n",
    "  - Keep only points with `Z > 0` (in front of camera).\n",
    "  - Normalized coords:\n",
    "      - `x_norm = X / Z`, `y_norm = Y / Z`.\n",
    "  - Homogeneous pixel coords:\n",
    "      - `[u; v; w] = K * [x_norm; y_norm; 1]`.\n",
    "  - Pixels:\n",
    "      - `u_px = u`, `v_px = v`.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Temporal association (LiDAR scan → camera frame)**\n",
    "\n",
    "2.1. For a given LiDAR scan at time `t_L` and time offset `tau`:\n",
    "  - Compute corresponding camera time:\n",
    "      - `t_C = t_L + tau`.\n",
    "\n",
    "2.2. Choose closest camera frame:\n",
    "  - Find index `k = argmin |cam_times[k] - t_C|`.\n",
    "  - Use `frame_id = frame_ids[k]`.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Per-scan edge alignment score**\n",
    "\n",
    "3.1. For each LiDAR scan in the chosen time window:\n",
    "  - Get LiDAR points `pts_L`.\n",
    "  - Optionally subsample to `max_points_per_scan` for speed.\n",
    "\n",
    "3.2. Transform to camera frame and project:\n",
    "  - `uv = lidar_points_to_pixels(pts_L_sub, T_CL, K)`.\n",
    "\n",
    "3.3. Query CameraPipeline distance transform:\n",
    "  - Use `pipeline.score_projection(frame_id, uv)`.\n",
    "  - This:\n",
    "      - Discards points outside the image.\n",
    "      - Looks up distance `d` to nearest edge for each projected point.\n",
    "      - Converts distances to scores via `exp(-d^2 / (2 * sigma^2))`.\n",
    "      - Sums all scores ⇒ `scan_score`.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Define global objective function**\n",
    "\n",
    "4.1. For a given `params = [tau, rx, ry, rz, tx, ty, tz]`:\n",
    "\n",
    "  - Initialize:\n",
    "      - `total_score = 0`\n",
    "      - `valid_count = 0`.\n",
    "\n",
    "  - For each chosen LiDAR scan index `i`:\n",
    "      1. Compute `scan_score_i` as in Step 3.\n",
    "      2. If `uv` is non-empty:\n",
    "          - `total_score += scan_score_i`\n",
    "          - `valid_count += 1`.\n",
    "\n",
    "4.2. If `valid_count == 0`:\n",
    "  - Return `objective = 0.0` (bad alignment).\n",
    "\n",
    "4.3. Else:\n",
    "  - `mean_score = total_score / valid_count`.\n",
    "  - Return:\n",
    "      - `objective(params) = -mean_score`\n",
    "      - (negative because optimizers *minimize*).\n",
    "\n",
    "---\n",
    "\n",
    "**Step 5: Optimization strategy**\n",
    "\n",
    "- **Stage 1: tau-only optimization**\n",
    "  1. Fix `rx, ry, rz, tx, ty, tz = 0`.\n",
    "  2. Optimize only `tau`:\n",
    "     - `minimize(tau_only_objective, x0=[0.0])`.\n",
    "  3. Get best time offset `tau*`.\n",
    "\n",
    "- **Stage 2: full joint refinement (optional)**\n",
    "  1. Start from:\n",
    "     - `x0_full = [tau*, 0, 0, 0, 0, 0, 0]`.\n",
    "  2. Optimize all 7 parameters:\n",
    "     - `minimize(joint_objective, x0_full, method=\"Powell\")`.\n",
    "  3. Final result:\n",
    "     - `tau*`, `R_delta*`, `t_delta*`.\n",
    "  4. Updated extrinsics:\n",
    "     - `T_CL_final = T_CL_init @ T_delta*`.\n",
    "\n",
    "Result:\n",
    "  - A time offset and LiDAR→camera transform that maximize LiDAR–camera edge alignment across the calibration time window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8570b-7639-4a26-85d3-7735ec131371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Small Euler -> rotation matrix ==========\n",
    "def euler_to_R(rx, ry, rz):\n",
    "    cx, sx = np.cos(rx), np.sin(rx)\n",
    "    cy, sy = np.cos(ry), np.sin(ry)\n",
    "    cz, sz = np.cos(rz), np.sin(rz)\n",
    "\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, cx, -sx],\n",
    "        [0, sx,  cx]\n",
    "    ])\n",
    "\n",
    "    Ry = np.array([\n",
    "        [ cy, 0, sy],\n",
    "        [  0, 1,  0],\n",
    "        [-sy, 0, cy]\n",
    "    ])\n",
    "\n",
    "    Rz = np.array([\n",
    "        [cz, -sz, 0],\n",
    "        [sz,  cz, 0],\n",
    "        [ 0,   0, 1]\n",
    "    ])\n",
    "\n",
    "    return Rz @ Ry @ Rx\n",
    "\n",
    "\n",
    "# ========== 2. Build 4x4 transform from R, t ==========\n",
    "def make_T(R, t):\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3]  = t.reshape(3,)\n",
    "    return T\n",
    "\n",
    "\n",
    "# ========== 3. LiDAR -> Camera frame ==========\n",
    "def transform_lidar_to_cam(points_L, T_CL):\n",
    "    if points_L.shape[0] == 0:\n",
    "        return np.zeros((0, 3), dtype=np.float32)\n",
    "\n",
    "    N = points_L.shape[0]\n",
    "    pts_L_h = np.hstack([points_L, np.ones((N, 1))])  # (N,4)\n",
    "    pts_C_h = (T_CL @ pts_L_h.T).T                    # (N,4)\n",
    "    return pts_C_h[:, :3]\n",
    "\n",
    "\n",
    "# ========== 4. Camera frame -> pixels using K ==========\n",
    "def project_cam_points_to_pixels(points_C, K):\n",
    "    if points_C.shape[0] == 0:\n",
    "        return np.zeros((0, 2), dtype=np.float32)\n",
    "\n",
    "    X = points_C[:, 0]\n",
    "    Y = points_C[:, 1]\n",
    "    Z = points_C[:, 2]\n",
    "\n",
    "    # Keep only points in front of camera\n",
    "    mask = Z > 0\n",
    "    X, Y, Z = X[mask], Y[mask], Z[mask]\n",
    "    if X.size == 0:\n",
    "        return np.zeros((0, 2), dtype=np.float32)\n",
    "\n",
    "    x_norm = X / Z\n",
    "    y_norm = Y / Z\n",
    "\n",
    "    pts_norm = np.vstack([x_norm, y_norm, np.ones_like(x_norm)])  # (3,M)\n",
    "    uv_h = K @ pts_norm                                            # (3,M)\n",
    "\n",
    "    u = uv_h[0, :]\n",
    "    v = uv_h[1, :]\n",
    "    uv = np.stack([u, v], axis=1).astype(np.float32)               # (M,2)\n",
    "    return uv\n",
    "\n",
    "\n",
    "# ========== 5. LiDAR points -> pixel coords ==========\n",
    "def lidar_points_to_pixels(points_L, T_CL, K):\n",
    "    points_C = transform_lidar_to_cam(points_L, T_CL)\n",
    "    uv = project_cam_points_to_pixels(points_C, K)\n",
    "    return uv\n",
    "\n",
    "\n",
    "# ========== 6. Choose closest camera frame for a given time ==========\n",
    "def closest_frame_id(cam_times, frame_ids, t_C):\n",
    "    idx = int(np.argmin(np.abs(cam_times - t_C)))\n",
    "    return int(frame_ids[idx])\n",
    "\n",
    "\n",
    "# ========== 7. Build joint optimization objective ==========\n",
    "def joint_objective(params,\n",
    "                    pipeline,\n",
    "                    lidar_scans,\n",
    "                    cam_times,\n",
    "                    frame_ids,\n",
    "                    K,\n",
    "                    T_CL_init,\n",
    "                    scan_indices=None,\n",
    "                    max_points_per_scan=5000):\n",
    "\n",
    "    cam_times = np.asarray(cam_times)\n",
    "    frame_ids = np.asarray(frame_ids)\n",
    "\n",
    "    if scan_indices is None:\n",
    "        scan_indices = np.arange(len(lidar_scans))\n",
    "    else:\n",
    "        scan_indices = np.asarray(scan_indices)\n",
    "\n",
    "    tau = params[0]\n",
    "    rx, ry, rz = params[1:4]\n",
    "    tx, ty, tz = params[4:7]\n",
    "\n",
    "    R_delta = euler_to_R(rx, ry, rz)\n",
    "    t_delta = np.array([tx, ty, tz], dtype=float)\n",
    "    T_delta = make_T(R_delta, t_delta)\n",
    "    T_CL = T_CL_init @ T_delta\n",
    "\n",
    "    total_score = 0.0\n",
    "    valid_count = 0\n",
    "\n",
    "    for idx in scan_indices:\n",
    "        scan = lidar_scans[idx]\n",
    "        t_L   = scan[\"timestamp_sec\"]\n",
    "        pts_L = scan[\"points\"]\n",
    "\n",
    "        if max_points_per_scan is not None and pts_L.shape[0] > max_points_per_scan:\n",
    "            choice = np.random.choice(pts_L.shape[0], max_points_per_scan, replace=False)\n",
    "            pts_L_sub = pts_L[choice]\n",
    "        else:\n",
    "            pts_L_sub = pts_L\n",
    "\n",
    "        t_C = t_L + tau\n",
    "        frame_id = closest_frame_id(cam_times, frame_ids, t_C)\n",
    "\n",
    "        uv = lidar_points_to_pixels(pts_L_sub, T_CL, K)\n",
    "        if uv.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        s = pipeline.score_projection(frame_id, uv)\n",
    "        total_score += s\n",
    "        valid_count += 1\n",
    "\n",
    "    if valid_count == 0:\n",
    "        return 0.0\n",
    "\n",
    "    mean_score = total_score / valid_count\n",
    "    return -mean_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed8880-7c93-412c-bb59-1f6598f99693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== helper functions ========\n",
    "# euler_to_R\n",
    "# make_T\n",
    "# transform_lidar_to_cam\n",
    "# project_cam_points_to_pixels\n",
    "# lidar_points_to_pixels\n",
    "# closest_frame_id\n",
    "# joint_objective   \n",
    "\n",
    "# ---------- tau-only wrapper ----------\n",
    "def tau_only_objective(tau_vec,\n",
    "                       pipeline,\n",
    "                       lidar_scans,\n",
    "                       cam_times,\n",
    "                       frame_ids,\n",
    "                       K,\n",
    "                       T_CL_init,\n",
    "                       scan_indices=None,\n",
    "                       max_points_per_scan=5000):\n",
    "    tau = float(tau_vec[0])\n",
    "\n",
    "    params = np.zeros(7, dtype=float)\n",
    "    params[0] = tau  # only tau is free, others = 0\n",
    "\n",
    "    return joint_objective(\n",
    "        params,\n",
    "        pipeline=pipeline,\n",
    "        lidar_scans=lidar_scans,\n",
    "        cam_times=cam_times,\n",
    "        frame_ids=frame_ids,\n",
    "        K=K,\n",
    "        T_CL_init=T_CL_init,\n",
    "        scan_indices=scan_indices,\n",
    "        max_points_per_scan=max_points_per_scan,\n",
    "    )\n",
    "\n",
    "# ============ LOAD ALL PRECOMPUTED DATA ============\n",
    "\n",
    "calib_dir = \"/home/aryaman/Forsyth_Data/calib_cache\"\n",
    "\n",
    "pipeline  = joblib.load(os.path.join(calib_dir, \"camera_pipeline.pkl\"))\n",
    "cam_times = np.load(os.path.join(calib_dir, \"cam_times.npy\"))\n",
    "frame_ids = np.load(os.path.join(calib_dir, \"frame_ids.npy\"))\n",
    "\n",
    "fx = 1501.9374712879626\n",
    "fy = 1498.8879775647906\n",
    "cx = 566.5690420612353\n",
    "cy = 537.1294320963829\n",
    "\n",
    "K = np.array([\n",
    "    [fx, 0.0, cx],\n",
    "    [0.0, fy, cy],\n",
    "    [0.0, 0.0, 1.0]\n",
    "], dtype=float)\n",
    "\n",
    "print(\"K =\\n\", K)\n",
    "\n",
    "lidar_scans_path = \"/home/aryaman/Forsyth_Data/lidar_scans.pkl\"\n",
    "lidar_scans = joblib.load(lidar_scans_path)\n",
    "\n",
    "T_CL_init = np.array([\n",
    "    [0.99919851,  0.04002921,  0.00000000,   0.15],\n",
    "    [0.00000000,  0.00000000, -1.00000000,  -0.2815789473684212],\n",
    "    [-0.04002921, 0.99919851,  0.00000000,  -0.13157894736842124],\n",
    "    [0.0,         0.0,         0.0,          1.0]\n",
    "], dtype=float)\n",
    "\n",
    "print(\"T_CL_init =\\n\", T_CL_init)\n",
    "\n",
    "# ============ STAGE 1: tau-only optimization ============\n",
    "\n",
    "x0_tau = np.array([0.0])  # initial tau\n",
    "\n",
    "print(\"\\n--- Stage 1: tau-only optimization ---\")\n",
    "res_tau = minimize(\n",
    "    tau_only_objective,\n",
    "    x0_tau,\n",
    "    args=(pipeline, lidar_scans, cam_times, frame_ids, K, T_CL_init, None, 5000),\n",
    "    method=\"Powell\"\n",
    ")\n",
    "best_tau = float(res_tau.x[0])\n",
    "print(\"Optimized tau =\", best_tau)\n",
    "print(\"Stage 1 objective =\", res_tau.fun)\n",
    "\n",
    "# ============ STAGE 2: full 7D optimization (optional) ============\n",
    "\n",
    "# If you want to *only* calibrate tau and keep R,t fixed, you can stop here.\n",
    "\n",
    "# Otherwise, refine all 7 starting from the tau we just found:\n",
    "x0_full = np.zeros(7)\n",
    "x0_full[0] = best_tau\n",
    "\n",
    "print(\"\\n--- Stage 2: full [tau, R, t] optimization ---\")\n",
    "res_full = minimize(\n",
    "    joint_objective,\n",
    "    x0_full,\n",
    "    args=(pipeline, lidar_scans, cam_times, frame_ids, K, T_CL_init, None, 5000),\n",
    "    method=\"Powell\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Optimization Complete ---\")\n",
    "print(\"Optimized params =\", res_full.x)\n",
    "print(\"Final objective   =\", res_full.fun)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (gtsam-venv)",
   "language": "python",
   "name": "gtsam-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
